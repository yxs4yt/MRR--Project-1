---
title: "DS 4002 Project 1"
author: "Morgan Simmons"
date: "2026-02-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#---------------------------
# 1) Read the raw dataset
#---------------------------

# read.csv() loads a CSV file from disk into an R data frame.
# Here, we’re reading the job postings dataset into an object named `jobs`.
# Purpose: get the raw data into R so we can clean and engineer features from it.
jobs <- read.csv("data_science_job_posts_2025.csv")


#---------------------------
# 2) Define your AI-skill "dictionary"
#---------------------------

# This is a character vector (a list of strings) containing the skill keywords
# you want to treat as “AI-related”.
# Purpose: later we’ll check each job’s listed skills against this vector
# and count how many matches occur.
ai_skills <- c(
  "machine learning",
  "deep learning",
  "neural network",
  "scikit-learn",
  "pytorch",
  "tensorflow",
  "numpy"
)

```

```{r}
#---------------------------
# 3) Load packages you need
#---------------------------

# tidyverse is a bundle of packages (dplyr, tidyr, stringr, ggplot2, etc.)
# that provide a consistent syntax for data manipulation.
# Purpose: we use dplyr verbs (%>%, select, filter, mutate, across),
# tidyr tools (separate), and stringr tools (str_remove_all, str_trim).
library(tidyverse)


#---------------------------
# 4) Clean + reshape the skills column
#---------------------------

# Start with the raw jobs data frame and pipe (%>%) it through a sequence
# of transformations. The pipe passes the current data frame to the next step.
jobs_clean <- jobs %>%
  
  # select() keeps only the columns you want to work with.
  # Purpose: reduce clutter and make the next steps faster/clearer.
  select(job_title, location, headquarter, industry, skills) %>%
  
  # filter() keeps only rows that meet a condition.
  # Here you keep rows where the `skills` column is not literally "[]".
  # Purpose: remove postings that have an empty skills list so ratios/counts
  # aren’t computed on meaningless skill sets.
  filter(skills != "[]") %>%
  
  # mutate() creates or modifies columns.
  # Here we overwrite `skills` by stripping out characters used to represent
  # lists/quotes, e.g. [ ] " '.
  #
  # str_remove_all() removes all matches of a regex from a string.
  # The pattern "\\[|\\]|\"|'" means:
  #   - \\[  : a literal '['
  #   - |    : OR
  #   - \\]  : a literal ']'
  #   - |\"  : a literal double quote
  #   - |'   : a literal single quote
  #
  # Purpose: convert something like ["python","numpy","sql"] into
  # something like python,numpy,sql so we can split it reliably.
  mutate(
    skills = str_remove_all(skills, "\\[|\\]|\"|'")
  ) %>%
  
  # separate() splits one column into multiple columns using a delimiter.
  # - into = c("skill_1","skill_2","skill_3"): the new column names
  # - sep = ",": split on commas
  # - extra = "drop": if there are MORE than 3 skills, discard the extras
  # - fill = "right": if there are FEWER than 3 skills, fill missing ones with NA
  #
  # Purpose: create fixed columns (skill_1..skill_3) so we can count skills
  # and compare them to ai_skills. This is a “wide” representation.
  separate(
    skills,
    into = c("skill_1", "skill_2", "skill_3"),
    sep = ",",
    extra = "drop",
    fill = "right"
  ) %>%
  
  # mutate(across(...)) applies a function to multiple columns at once.
  # - starts_with("skill_") picks columns skill_1, skill_2, skill_3
  # - str_trim() removes leading/trailing whitespace
  #
  # Purpose: after separating, skills often look like " numpy" or "sql "
  # which would fail exact matching unless we trim whitespace.
  mutate(across(starts_with("skill_"), str_trim))


#---------------------------
# 5) Feature engineering: totals + AI counts + ratios
#---------------------------

jobs_clean <- jobs_clean %>%
  
  # mutate() again to add computed columns:
  mutate(
    # total_skills:
    # We want to count how many skill columns are actually present (not NA) per row.
    #
    # across(starts_with("skill_")) returns the skill columns.
    # is.na(...) checks which entries are NA.
    # !is.na(...) converts that into TRUE for "has a value", FALSE for NA.
    # rowSums(...) adds up TRUE/FALSE across columns for each row
    # (TRUE counts as 1, FALSE counts as 0).
    #
    # Purpose: know the denominator for the AI ratio.
    total_skills = rowSums(!is.na(across(starts_with("skill_")))),
    
    # ai_skill_count:
    # We check each skill column to see if it appears in the ai_skills vector.
    #
    # across(..., ~ .x %in% ai_skills) applies the expression to each skill column:
    #   - .x is the column vector
    #   - %in% returns TRUE if the skill is exactly one of ai_skills, else FALSE
    #
    # rowSums(..., na.rm = TRUE) then counts how many TRUEs are in that row.
    # na.rm = TRUE ensures NAs don’t break the sum.
    #
    # Purpose: count how many of the listed skills are AI-related.
    ai_skill_count = rowSums(
      across(starts_with("skill_"), ~ .x %in% ai_skills),
      na.rm = TRUE
    ),
    
    # ai_skill_ratio:
    # A simple proportion: (# AI skills) / (total # skills).
    #
    # Purpose: normalize AI emphasis so postings with 1 skill vs 3 skills
    # are comparable.
    ai_skill_ratio = ai_skill_count / total_skills
  )

```

